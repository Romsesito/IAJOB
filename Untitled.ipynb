{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b539e5-7b0a-4590-8d35-878dd9fcf026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12692839-fb7d-430e-ba48-36a0a9d678dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/MiltonDavila123/CSV/refs/heads/main/ai_job_dataset.csv\")\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "849fac0e-2a99-494a-8494-7a7352303fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        job_id                    job_title  salary_usd salary_currency  \\\n",
      "0      AI00001        AI Research Scientist       90376             USD   \n",
      "1      AI00002         AI Software Engineer       61895             USD   \n",
      "2      AI00003                AI Specialist      152626             USD   \n",
      "3      AI00004                 NLP Engineer       80215             USD   \n",
      "4      AI00005                AI Consultant       54624             EUR   \n",
      "...        ...                          ...         ...             ...   \n",
      "14995  AI14996            Robotics Engineer       38604             USD   \n",
      "14996  AI14997  Machine Learning Researcher       57811             GBP   \n",
      "14997  AI14998                 NLP Engineer      189490             USD   \n",
      "14998  AI14999                   Head of AI       79461             EUR   \n",
      "14999  AI15000     Computer Vision Engineer       56481             USD   \n",
      "\n",
      "      experience_level employment_type company_location company_size  \\\n",
      "0                   SE              CT            China            M   \n",
      "1                   EN              CT           Canada            M   \n",
      "2                   MI              FL      Switzerland            L   \n",
      "3                   SE              FL            India            M   \n",
      "4                   EN              PT           France            S   \n",
      "...                ...             ...              ...          ...   \n",
      "14995               EN              FL          Finland            S   \n",
      "14996               EN              CT   United Kingdom            M   \n",
      "14997               EX              CT      South Korea            L   \n",
      "14998               EN              FT      Netherlands            M   \n",
      "14999               MI              PT          Austria            S   \n",
      "\n",
      "      employee_residence  remote_ratio  \\\n",
      "0                  China            50   \n",
      "1                Ireland           100   \n",
      "2            South Korea             0   \n",
      "3                  India            50   \n",
      "4              Singapore           100   \n",
      "...                  ...           ...   \n",
      "14995            Finland            50   \n",
      "14996     United Kingdom             0   \n",
      "14997        South Korea            50   \n",
      "14998        Netherlands             0   \n",
      "14999            Austria            50   \n",
      "\n",
      "                                       required_skills education_required  \\\n",
      "0             Tableau, PyTorch, Kubernetes, Linux, NLP           Bachelor   \n",
      "1      Deep Learning, AWS, Mathematics, Python, Docker             Master   \n",
      "2         Kubernetes, Deep Learning, Java, Hadoop, NLP          Associate   \n",
      "3                            Scala, SQL, Linux, Python                PhD   \n",
      "4                         MLOps, Java, Tableau, Python             Master   \n",
      "...                                                ...                ...   \n",
      "14995                          Java, Kubernetes, Azure           Bachelor   \n",
      "14996          Mathematics, Docker, SQL, Deep Learning             Master   \n",
      "14997                                Scala, Spark, NLP          Associate   \n",
      "14998        Java, Computer Vision, Python, TensorFlow                PhD   \n",
      "14999    Scala, Azure, Deep Learning, GCP, Mathematics                PhD   \n",
      "\n",
      "       years_experience       industry posting_date application_deadline  \\\n",
      "0                     9     Automotive   2024-10-18           2024-11-07   \n",
      "1                     1          Media   2024-11-20           2025-01-11   \n",
      "2                     2      Education   2025-03-18           2025-04-07   \n",
      "3                     7     Consulting   2024-12-23           2025-02-24   \n",
      "4                     0          Media   2025-04-15           2025-06-23   \n",
      "...                 ...            ...          ...                  ...   \n",
      "14995                 1         Energy   2025-02-06           2025-03-25   \n",
      "14996                 0     Government   2024-10-16           2024-10-30   \n",
      "14997                17  Manufacturing   2024-03-19           2024-05-02   \n",
      "14998                 1    Real Estate   2024-03-22           2024-04-23   \n",
      "14999                 2     Technology   2024-07-18           2024-08-10   \n",
      "\n",
      "       job_description_length  benefits_score       company_name  \n",
      "0                        1076             5.9    Smart Analytics  \n",
      "1                        1268             5.2       TechCorp Inc  \n",
      "2                        1974             9.4    Autonomous Tech  \n",
      "3                        1345             8.6     Future Systems  \n",
      "4                        1989             6.6  Advanced Robotics  \n",
      "...                       ...             ...                ...  \n",
      "14995                    1635             7.9  Advanced Robotics  \n",
      "14996                    1624             8.2    Smart Analytics  \n",
      "14997                    1336             7.4     AI Innovations  \n",
      "14998                    1935             5.6    Smart Analytics  \n",
      "14999                    2492             7.6     AI Innovations  \n",
      "\n",
      "[15000 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8371576-08d4-49bc-94a8-d97964f06b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['years_experience', 'remote_ratio','benefits_score','experience_level','employment_type','company_size','education_required','company_location',\n",
    "        'industry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62b2922b-4373-42aa-a697-229dc22a888d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       years_experience  remote_ratio  benefits_score experience_level  \\\n",
      "0                     9            50             5.9               SE   \n",
      "1                     1           100             5.2               EN   \n",
      "2                     2             0             9.4               MI   \n",
      "3                     7            50             8.6               SE   \n",
      "4                     0           100             6.6               EN   \n",
      "...                 ...           ...             ...              ...   \n",
      "14995                 1            50             7.9               EN   \n",
      "14996                 0             0             8.2               EN   \n",
      "14997                17            50             7.4               EX   \n",
      "14998                 1             0             5.6               EN   \n",
      "14999                 2            50             7.6               MI   \n",
      "\n",
      "      employment_type company_size education_required company_location  \\\n",
      "0                  CT            M           Bachelor            China   \n",
      "1                  CT            M             Master           Canada   \n",
      "2                  FL            L          Associate      Switzerland   \n",
      "3                  FL            M                PhD            India   \n",
      "4                  PT            S             Master           France   \n",
      "...               ...          ...                ...              ...   \n",
      "14995              FL            S           Bachelor          Finland   \n",
      "14996              CT            M             Master   United Kingdom   \n",
      "14997              CT            L          Associate      South Korea   \n",
      "14998              FT            M                PhD      Netherlands   \n",
      "14999              PT            S                PhD          Austria   \n",
      "\n",
      "            industry  \n",
      "0         Automotive  \n",
      "1              Media  \n",
      "2          Education  \n",
      "3         Consulting  \n",
      "4              Media  \n",
      "...              ...  \n",
      "14995         Energy  \n",
      "14996     Government  \n",
      "14997  Manufacturing  \n",
      "14998    Real Estate  \n",
      "14999     Technology  \n",
      "\n",
      "[15000 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e74deb3a-3eef-48a7-87c5-2a859b610348",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['salary_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d1c72de-6afd-482a-9701-529c0d324b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         90376\n",
      "1         61895\n",
      "2        152626\n",
      "3         80215\n",
      "4         54624\n",
      "          ...  \n",
      "14995     38604\n",
      "14996     57811\n",
      "14997    189490\n",
      "14998     79461\n",
      "14999     56481\n",
      "Name: salary_usd, Length: 15000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10eb39f5-5faf-4ffd-a6e6-ac6789db4755",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_categoricas = ['experience_level','employment_type','company_size','education_required','company_location',\n",
    "        'industry']\n",
    "variable_numericas= ['years_experience', 'remote_ratio','benefits_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05b265fb-56de-49a3-849d-74b774e163b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), variable_numericas),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), variables_categoricas)\n",
    "    ])\n",
    "\n",
    "X_processed = preprocessor.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e05bdc04-8535-4df8-abc2-7d6f31d04978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.49531313  0.01265988 -1.10576909 ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.94727643  1.23780922 -1.58825443 ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.76695274 -1.21248946  1.3066576  ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 1.93790268  0.01265988 -0.07187194 ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.94727643 -1.21248946 -1.31254852 ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.76695274  0.01265988  0.06598102 ...  1.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c581039-8a2a-4a1a-b8b3-e66662867a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ba1b0e9-bba9-4ca4-9172-5e420f7fc1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Milton Davila\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eca140df-1eb1-420f-8927-9bfc905da624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando la red neuronal...\n",
      "Epoch 1/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 16488583168.0000 - mae: 113533.1328 - val_loss: 15999350784.0000 - val_mae: 111471.5547\n",
      "Epoch 2/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 10092120064.0000 - mae: 80639.8125 - val_loss: 4046910464.0000 - val_mae: 43610.0781\n",
      "Epoch 3/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2260114432.0000 - mae: 33825.1992 - val_loss: 1684868864.0000 - val_mae: 30453.0059\n",
      "Epoch 4/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1442409728.0000 - mae: 27945.4609 - val_loss: 1249035776.0000 - val_mae: 25644.3730\n",
      "Epoch 5/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1121869824.0000 - mae: 23617.7559 - val_loss: 1023470336.0000 - val_mae: 22066.0527\n",
      "Epoch 6/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 950000704.0000 - mae: 20898.4121 - val_loss: 895907392.0000 - val_mae: 20211.2930\n",
      "Epoch 7/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 848861568.0000 - mae: 19500.7441 - val_loss: 813074560.0000 - val_mae: 19191.9160\n",
      "Epoch 8/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 780322176.0000 - mae: 18695.4375 - val_loss: 757728768.0000 - val_mae: 18750.7910\n",
      "Epoch 9/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 731357760.0000 - mae: 18275.0293 - val_loss: 711050304.0000 - val_mae: 18095.0625\n",
      "Epoch 10/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 694487808.0000 - mae: 17992.5078 - val_loss: 678243392.0000 - val_mae: 17789.1055\n",
      "Epoch 11/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 666986432.0000 - mae: 17780.7852 - val_loss: 655533696.0000 - val_mae: 17737.7715\n",
      "Epoch 12/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 647077056.0000 - mae: 17736.0703 - val_loss: 636491392.0000 - val_mae: 17499.8359\n",
      "Epoch 13/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 630338048.0000 - mae: 17628.9629 - val_loss: 621860800.0000 - val_mae: 17525.7207\n",
      "Epoch 14/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 618714432.0000 - mae: 17624.7715 - val_loss: 610664000.0000 - val_mae: 17468.6992\n",
      "Epoch 15/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 608036608.0000 - mae: 17549.6328 - val_loss: 601731328.0000 - val_mae: 17300.3691\n",
      "Epoch 16/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 598387648.0000 - mae: 17438.6992 - val_loss: 591813504.0000 - val_mae: 17326.5352\n",
      "Epoch 17/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 589105920.0000 - mae: 17394.0547 - val_loss: 584254976.0000 - val_mae: 17086.3066\n",
      "Epoch 18/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 578729216.0000 - mae: 17214.0859 - val_loss: 573237312.0000 - val_mae: 17019.9941\n",
      "Epoch 19/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 570029056.0000 - mae: 17118.4434 - val_loss: 563659456.0000 - val_mae: 16911.7402\n",
      "Epoch 20/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 560217600.0000 - mae: 16955.4492 - val_loss: 554850496.0000 - val_mae: 16838.7930\n",
      "Epoch 21/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 550663808.0000 - mae: 16815.9258 - val_loss: 545804864.0000 - val_mae: 16694.2695\n",
      "Epoch 22/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 541288576.0000 - mae: 16687.0430 - val_loss: 537511936.0000 - val_mae: 16512.6289\n",
      "Epoch 23/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 532263520.0000 - mae: 16522.6426 - val_loss: 530126976.0000 - val_mae: 16502.2773\n",
      "Epoch 24/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 523746336.0000 - mae: 16423.1348 - val_loss: 521733024.0000 - val_mae: 16309.2998\n",
      "Epoch 25/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 515528800.0000 - mae: 16277.0000 - val_loss: 518098720.0000 - val_mae: 16181.3467\n",
      "Epoch 26/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 507559104.0000 - mae: 16184.4502 - val_loss: 506767328.0000 - val_mae: 16087.8604\n",
      "Epoch 27/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 499734720.0000 - mae: 16042.7734 - val_loss: 498646656.0000 - val_mae: 16043.8848\n",
      "Epoch 28/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 491782528.0000 - mae: 15939.1387 - val_loss: 492208352.0000 - val_mae: 16004.7197\n",
      "Epoch 29/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 484630688.0000 - mae: 15840.9482 - val_loss: 484678272.0000 - val_mae: 15839.7637\n",
      "Epoch 30/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 477717248.0000 - mae: 15738.5430 - val_loss: 479111744.0000 - val_mae: 15809.4648\n",
      "Epoch 31/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 471329984.0000 - mae: 15643.5771 - val_loss: 472640768.0000 - val_mae: 15678.9463\n",
      "Epoch 32/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 464843840.0000 - mae: 15554.3730 - val_loss: 466851712.0000 - val_mae: 15610.0381\n",
      "Epoch 33/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 459072864.0000 - mae: 15432.9268 - val_loss: 462124160.0000 - val_mae: 15500.5303\n",
      "Epoch 34/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 453743232.0000 - mae: 15342.3662 - val_loss: 456213856.0000 - val_mae: 15443.2754\n",
      "Epoch 35/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 448858752.0000 - mae: 15264.3203 - val_loss: 452442816.0000 - val_mae: 15392.7969\n",
      "Epoch 36/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 443229376.0000 - mae: 15174.5029 - val_loss: 446960608.0000 - val_mae: 15312.9404\n",
      "Epoch 37/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 438536192.0000 - mae: 15084.2002 - val_loss: 444144864.0000 - val_mae: 15291.7754\n",
      "Epoch 38/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 434704928.0000 - mae: 15033.0264 - val_loss: 440918816.0000 - val_mae: 15157.2529\n",
      "Epoch 39/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 429836032.0000 - mae: 14922.5264 - val_loss: 435046048.0000 - val_mae: 15120.3184\n",
      "Epoch 40/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 425662208.0000 - mae: 14891.2646 - val_loss: 433692864.0000 - val_mae: 15045.4834\n",
      "Epoch 41/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 422420064.0000 - mae: 14790.4980 - val_loss: 428819456.0000 - val_mae: 14991.8682\n",
      "Epoch 42/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 419578048.0000 - mae: 14748.6133 - val_loss: 426334400.0000 - val_mae: 14948.9365\n",
      "Epoch 43/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 416226592.0000 - mae: 14688.9785 - val_loss: 423830400.0000 - val_mae: 14902.1230\n",
      "Epoch 44/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 413956576.0000 - mae: 14628.1914 - val_loss: 420598048.0000 - val_mae: 14864.7314\n",
      "Epoch 45/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 411092448.0000 - mae: 14589.1904 - val_loss: 419219040.0000 - val_mae: 14820.0283\n",
      "Epoch 46/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 409111168.0000 - mae: 14553.2031 - val_loss: 416685056.0000 - val_mae: 14799.7695\n",
      "Epoch 47/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 406579648.0000 - mae: 14524.7188 - val_loss: 415934816.0000 - val_mae: 14784.1162\n",
      "Epoch 48/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 405262752.0000 - mae: 14492.5234 - val_loss: 413860096.0000 - val_mae: 14747.7402\n",
      "Epoch 49/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 403521760.0000 - mae: 14469.1396 - val_loss: 414612416.0000 - val_mae: 14723.5283\n",
      "Epoch 50/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 401358144.0000 - mae: 14429.7051 - val_loss: 411635360.0000 - val_mae: 14712.7383\n",
      "Epoch 51/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 400826208.0000 - mae: 14418.3418 - val_loss: 412261440.0000 - val_mae: 14690.7969\n",
      "Epoch 52/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 399308480.0000 - mae: 14393.7480 - val_loss: 410959744.0000 - val_mae: 14707.2695\n",
      "Epoch 53/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 398148864.0000 - mae: 14380.2051 - val_loss: 409482304.0000 - val_mae: 14666.9482\n",
      "Epoch 54/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 397226112.0000 - mae: 14360.7100 - val_loss: 409918272.0000 - val_mae: 14663.9746\n",
      "Epoch 55/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 396109984.0000 - mae: 14339.5518 - val_loss: 408479648.0000 - val_mae: 14642.4629\n",
      "Epoch 56/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 395408832.0000 - mae: 14336.3271 - val_loss: 408203232.0000 - val_mae: 14644.4570\n",
      "Epoch 57/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 395108704.0000 - mae: 14322.4863 - val_loss: 407186688.0000 - val_mae: 14622.3633\n",
      "Epoch 58/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 394383456.0000 - mae: 14305.0430 - val_loss: 407476800.0000 - val_mae: 14612.0986\n",
      "Epoch 59/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 393586464.0000 - mae: 14294.5664 - val_loss: 408491744.0000 - val_mae: 14623.0732\n",
      "Epoch 60/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 392318496.0000 - mae: 14269.0469 - val_loss: 407409120.0000 - val_mae: 14633.3281\n",
      "Epoch 61/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 392325408.0000 - mae: 14275.5664 - val_loss: 406297728.0000 - val_mae: 14600.8350\n",
      "Epoch 62/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 391931616.0000 - mae: 14264.9697 - val_loss: 406322560.0000 - val_mae: 14606.3887\n",
      "Epoch 63/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 391228224.0000 - mae: 14256.6514 - val_loss: 406900256.0000 - val_mae: 14616.5049\n",
      "Epoch 64/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 390781408.0000 - mae: 14238.5869 - val_loss: 405433504.0000 - val_mae: 14584.4951\n",
      "Epoch 65/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 390550240.0000 - mae: 14243.6270 - val_loss: 406052832.0000 - val_mae: 14585.8447\n",
      "Epoch 66/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 389792800.0000 - mae: 14232.8604 - val_loss: 405492384.0000 - val_mae: 14581.4385\n",
      "Epoch 67/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 389453280.0000 - mae: 14221.9951 - val_loss: 405356704.0000 - val_mae: 14581.1553\n",
      "Epoch 68/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 388573088.0000 - mae: 14199.0664 - val_loss: 404993440.0000 - val_mae: 14570.0068\n",
      "Epoch 69/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 388665504.0000 - mae: 14204.9014 - val_loss: 405454208.0000 - val_mae: 14575.7021\n",
      "Epoch 70/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 388322144.0000 - mae: 14196.4150 - val_loss: 404971968.0000 - val_mae: 14567.1133\n",
      "Epoch 71/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 387835008.0000 - mae: 14183.5352 - val_loss: 404972224.0000 - val_mae: 14563.6621\n",
      "Epoch 72/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 387158496.0000 - mae: 14179.4385 - val_loss: 404314048.0000 - val_mae: 14559.3047\n",
      "Epoch 73/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 387579616.0000 - mae: 14195.9248 - val_loss: 405296512.0000 - val_mae: 14562.6963\n",
      "Epoch 74/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 386639264.0000 - mae: 14160.0781 - val_loss: 405173568.0000 - val_mae: 14575.6562\n",
      "Epoch 75/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 386500320.0000 - mae: 14164.7080 - val_loss: 404117632.0000 - val_mae: 14547.3564\n",
      "Epoch 76/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 386710336.0000 - mae: 14163.6084 - val_loss: 406255328.0000 - val_mae: 14574.1279\n",
      "Epoch 77/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 385812384.0000 - mae: 14145.8535 - val_loss: 404151200.0000 - val_mae: 14557.8330\n",
      "Epoch 78/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 385688224.0000 - mae: 14152.4414 - val_loss: 405320320.0000 - val_mae: 14565.2051\n",
      "Epoch 79/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 385143680.0000 - mae: 14132.9971 - val_loss: 404659360.0000 - val_mae: 14549.3115\n",
      "Epoch 80/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 384510272.0000 - mae: 14131.8770 - val_loss: 414990784.0000 - val_mae: 14669.0430\n",
      "Epoch 81/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 385941440.0000 - mae: 14150.0869 - val_loss: 405872352.0000 - val_mae: 14561.5283\n",
      "Epoch 82/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 384195424.0000 - mae: 14115.3555 - val_loss: 404925984.0000 - val_mae: 14560.4404\n",
      "Epoch 83/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 384134144.0000 - mae: 14120.3271 - val_loss: 404053312.0000 - val_mae: 14542.4004\n",
      "Epoch 84/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 384772384.0000 - mae: 14126.5332 - val_loss: 408256128.0000 - val_mae: 14593.6035\n",
      "Epoch 85/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 384345184.0000 - mae: 14121.7734 - val_loss: 404117056.0000 - val_mae: 14543.0068\n",
      "Epoch 86/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 383536128.0000 - mae: 14113.4736 - val_loss: 403394848.0000 - val_mae: 14528.0479\n",
      "Epoch 87/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 383346464.0000 - mae: 14103.5029 - val_loss: 403967136.0000 - val_mae: 14537.5801\n",
      "Epoch 88/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 383646912.0000 - mae: 14112.6055 - val_loss: 405248832.0000 - val_mae: 14553.1582\n",
      "Epoch 89/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 382756608.0000 - mae: 14091.8750 - val_loss: 403447520.0000 - val_mae: 14526.3096\n",
      "Epoch 90/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 383020992.0000 - mae: 14098.3447 - val_loss: 404336288.0000 - val_mae: 14548.4570\n",
      "Epoch 91/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 382724800.0000 - mae: 14090.3965 - val_loss: 406578368.0000 - val_mae: 14565.3086\n",
      "Epoch 92/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 382400864.0000 - mae: 14082.1436 - val_loss: 403687904.0000 - val_mae: 14531.2246\n",
      "Epoch 93/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 382073376.0000 - mae: 14081.9668 - val_loss: 403907872.0000 - val_mae: 14530.3965\n",
      "Epoch 94/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 382402720.0000 - mae: 14080.9004 - val_loss: 403025504.0000 - val_mae: 14519.5615\n",
      "Epoch 95/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 382095264.0000 - mae: 14066.9648 - val_loss: 403169920.0000 - val_mae: 14516.9385\n",
      "Epoch 96/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 382650144.0000 - mae: 14084.3203 - val_loss: 403693120.0000 - val_mae: 14523.3652\n",
      "Epoch 97/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 382637440.0000 - mae: 14090.9570 - val_loss: 403275840.0000 - val_mae: 14521.9746\n",
      "Epoch 98/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 382375520.0000 - mae: 14074.8887 - val_loss: 403174400.0000 - val_mae: 14514.6768\n",
      "Epoch 99/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 381764608.0000 - mae: 14070.5801 - val_loss: 404627072.0000 - val_mae: 14537.1982\n",
      "Epoch 100/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 381642656.0000 - mae: 14075.5869 - val_loss: 406343872.0000 - val_mae: 14558.1152\n",
      "Epoch 101/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 381876672.0000 - mae: 14066.5664 - val_loss: 404099584.0000 - val_mae: 14528.3613\n",
      "Epoch 102/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 381254048.0000 - mae: 14063.8867 - val_loss: 407672256.0000 - val_mae: 14575.4463\n",
      "Epoch 103/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 380641600.0000 - mae: 14049.6133 - val_loss: 404672992.0000 - val_mae: 14539.7803\n",
      "Epoch 104/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 381690208.0000 - mae: 14059.2354 - val_loss: 405835904.0000 - val_mae: 14567.3867\n",
      "Epoch 105/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 381294080.0000 - mae: 14059.6904 - val_loss: 406562528.0000 - val_mae: 14559.9297\n",
      "Epoch 106/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 380976096.0000 - mae: 14066.4648 - val_loss: 405125568.0000 - val_mae: 14541.3350\n",
      "Epoch 107/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 380966816.0000 - mae: 14060.9365 - val_loss: 403837760.0000 - val_mae: 14526.4062\n",
      "Epoch 108/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 380300480.0000 - mae: 14049.2715 - val_loss: 403986976.0000 - val_mae: 14525.9932\n",
      "Epoch 109/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 380842816.0000 - mae: 14058.5303 - val_loss: 403536320.0000 - val_mae: 14522.1631\n",
      "Epoch 110/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 380656640.0000 - mae: 14048.0947 - val_loss: 405869728.0000 - val_mae: 14559.0166\n",
      "Epoch 111/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 380519520.0000 - mae: 14049.1670 - val_loss: 404292992.0000 - val_mae: 14534.7197\n",
      "Epoch 112/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 380276736.0000 - mae: 14044.3936 - val_loss: 406449152.0000 - val_mae: 14561.8418\n",
      "Epoch 113/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 380125888.0000 - mae: 14032.4629 - val_loss: 403611552.0000 - val_mae: 14520.8281\n",
      "Epoch 114/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 379920128.0000 - mae: 14046.5352 - val_loss: 404815168.0000 - val_mae: 14550.9619\n",
      "Epoch 115/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 380132320.0000 - mae: 14039.0898 - val_loss: 403627552.0000 - val_mae: 14517.6348\n",
      "Epoch 116/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 380148640.0000 - mae: 14046.2051 - val_loss: 404113536.0000 - val_mae: 14530.2803\n",
      "Epoch 117/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 379952800.0000 - mae: 14027.1562 - val_loss: 404224384.0000 - val_mae: 14528.1982\n",
      "Epoch 118/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 379919488.0000 - mae: 14030.0771 - val_loss: 404008320.0000 - val_mae: 14524.6396\n",
      "Epoch 119/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 380070560.0000 - mae: 14034.2432 - val_loss: 404247776.0000 - val_mae: 14527.0137\n",
      "Epoch 120/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 379939488.0000 - mae: 14030.1104 - val_loss: 405130080.0000 - val_mae: 14538.6113\n",
      "Epoch 121/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 379712864.0000 - mae: 14036.1221 - val_loss: 404494400.0000 - val_mae: 14526.2549\n",
      "Epoch 122/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 379685152.0000 - mae: 14020.2451 - val_loss: 405444800.0000 - val_mae: 14552.1748\n",
      "Epoch 123/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 379354368.0000 - mae: 14019.9697 - val_loss: 404710848.0000 - val_mae: 14539.1250\n",
      "Epoch 124/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 379352384.0000 - mae: 14011.8232 - val_loss: 406866304.0000 - val_mae: 14561.6553\n",
      "Epoch 125/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 379256448.0000 - mae: 14021.5518 - val_loss: 404193184.0000 - val_mae: 14526.8418\n",
      "Epoch 126/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 379162560.0000 - mae: 14020.5146 - val_loss: 407649920.0000 - val_mae: 14569.6230\n",
      "Epoch 127/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 379040512.0000 - mae: 14010.7402 - val_loss: 404691040.0000 - val_mae: 14535.5430\n",
      "Epoch 128/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 379027200.0000 - mae: 14014.4287 - val_loss: 404229600.0000 - val_mae: 14524.3018\n",
      "Epoch 129/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 379297088.0000 - mae: 14010.9863 - val_loss: 404331200.0000 - val_mae: 14528.5400\n",
      "Epoch 130/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 378914720.0000 - mae: 14017.3271 - val_loss: 404861856.0000 - val_mae: 14541.7812\n",
      "Epoch 131/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 378861824.0000 - mae: 14010.4912 - val_loss: 404313824.0000 - val_mae: 14531.0381\n",
      "Epoch 132/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 378606464.0000 - mae: 14016.5654 - val_loss: 404734144.0000 - val_mae: 14530.5371\n",
      "Epoch 133/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 379035168.0000 - mae: 14007.0000 - val_loss: 404536032.0000 - val_mae: 14521.7715\n",
      "Epoch 134/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 378166368.0000 - mae: 13996.3086 - val_loss: 404418272.0000 - val_mae: 14523.0547\n",
      "Epoch 135/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 378860192.0000 - mae: 14001.1816 - val_loss: 404593184.0000 - val_mae: 14532.4082\n",
      "Epoch 136/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 378543584.0000 - mae: 14005.0186 - val_loss: 406822240.0000 - val_mae: 14560.2832\n",
      "Epoch 137/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 378312992.0000 - mae: 13998.0146 - val_loss: 406227360.0000 - val_mae: 14556.5000\n",
      "Epoch 138/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 378773280.0000 - mae: 14012.0518 - val_loss: 404650528.0000 - val_mae: 14528.6504\n",
      "Epoch 139/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 378290272.0000 - mae: 13993.2236 - val_loss: 405352128.0000 - val_mae: 14550.8838\n",
      "Epoch 140/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 378474016.0000 - mae: 13998.0479 - val_loss: 406258144.0000 - val_mae: 14551.7148\n",
      "Epoch 141/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 378325088.0000 - mae: 13999.8516 - val_loss: 407117408.0000 - val_mae: 14560.4014\n",
      "Epoch 142/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 378102560.0000 - mae: 13995.5947 - val_loss: 407147968.0000 - val_mae: 14557.0518\n",
      "Epoch 143/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 379285696.0000 - mae: 14014.9053 - val_loss: 408479392.0000 - val_mae: 14576.1621\n",
      "Epoch 144/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 378168000.0000 - mae: 13992.8496 - val_loss: 408512704.0000 - val_mae: 14577.3184\n",
      "Epoch 145/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 378532576.0000 - mae: 13998.7334 - val_loss: 404376032.0000 - val_mae: 14520.1621\n",
      "Epoch 146/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 377304800.0000 - mae: 13982.4219 - val_loss: 406418272.0000 - val_mae: 14547.2852\n",
      "Epoch 147/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 378280608.0000 - mae: 14003.3018 - val_loss: 404343488.0000 - val_mae: 14523.5879\n",
      "Epoch 148/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 377944832.0000 - mae: 13993.7588 - val_loss: 404616928.0000 - val_mae: 14527.6748\n",
      "Epoch 149/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 378392896.0000 - mae: 13986.4004 - val_loss: 404774464.0000 - val_mae: 14532.5938\n",
      "Epoch 150/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 377734208.0000 - mae: 13987.3682 - val_loss: 404473664.0000 - val_mae: 14527.7021\n",
      "Epoch 151/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 377376736.0000 - mae: 13985.4434 - val_loss: 405380352.0000 - val_mae: 14542.7529\n",
      "Epoch 152/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 377471616.0000 - mae: 13980.8838 - val_loss: 409666816.0000 - val_mae: 14584.3330\n",
      "Epoch 153/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 377622336.0000 - mae: 13996.0303 - val_loss: 405201600.0000 - val_mae: 14536.7871\n",
      "Epoch 154/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 377614176.0000 - mae: 13972.3535 - val_loss: 407195360.0000 - val_mae: 14568.3682\n",
      "Epoch 155/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 377631744.0000 - mae: 13989.2314 - val_loss: 404749280.0000 - val_mae: 14530.8154\n",
      "Epoch 156/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 377893408.0000 - mae: 13985.2471 - val_loss: 404674624.0000 - val_mae: 14531.4229\n",
      "Epoch 157/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 377496640.0000 - mae: 13991.7217 - val_loss: 404830080.0000 - val_mae: 14529.0703\n",
      "Epoch 158/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 377232480.0000 - mae: 13975.5029 - val_loss: 406328864.0000 - val_mae: 14547.7598\n",
      "Epoch 159/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 377651392.0000 - mae: 13987.0850 - val_loss: 409216160.0000 - val_mae: 14577.6865\n",
      "Epoch 160/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 377524448.0000 - mae: 13977.2842 - val_loss: 405047136.0000 - val_mae: 14532.0586\n",
      "Epoch 161/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 377466816.0000 - mae: 13977.5244 - val_loss: 407281664.0000 - val_mae: 14563.2402\n",
      "Epoch 162/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 377520736.0000 - mae: 13976.7441 - val_loss: 408317312.0000 - val_mae: 14571.5020\n",
      "Epoch 163/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 377073440.0000 - mae: 13970.5781 - val_loss: 405436288.0000 - val_mae: 14543.9600\n",
      "Epoch 164/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 376447424.0000 - mae: 13963.8330 - val_loss: 405525568.0000 - val_mae: 14534.7637\n",
      "Epoch 165/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 376579744.0000 - mae: 13969.2988 - val_loss: 404671488.0000 - val_mae: 14517.2129\n",
      "Epoch 166/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 376663136.0000 - mae: 13960.2686 - val_loss: 405192704.0000 - val_mae: 14529.9551\n",
      "Epoch 167/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 376572512.0000 - mae: 13959.4004 - val_loss: 404948480.0000 - val_mae: 14524.5117\n",
      "Epoch 168/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 376599008.0000 - mae: 13969.5352 - val_loss: 404828576.0000 - val_mae: 14524.4932\n",
      "Epoch 169/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 376741696.0000 - mae: 13975.2598 - val_loss: 408434240.0000 - val_mae: 14568.3887\n",
      "Epoch 170/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 377348000.0000 - mae: 13983.9053 - val_loss: 405679552.0000 - val_mae: 14539.8350\n",
      "Epoch 171/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 376768640.0000 - mae: 13961.5234 - val_loss: 405492096.0000 - val_mae: 14539.7148\n",
      "Epoch 172/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 376676864.0000 - mae: 13963.6064 - val_loss: 405791200.0000 - val_mae: 14542.5498\n",
      "Epoch 173/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 376886208.0000 - mae: 13976.9688 - val_loss: 404929280.0000 - val_mae: 14528.2568\n",
      "Epoch 174/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 376172256.0000 - mae: 13957.8818 - val_loss: 405743296.0000 - val_mae: 14539.6416\n",
      "Epoch 175/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 376638016.0000 - mae: 13975.4727 - val_loss: 407266432.0000 - val_mae: 14556.9883\n",
      "Epoch 176/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 376507776.0000 - mae: 13956.9951 - val_loss: 405290080.0000 - val_mae: 14527.9053\n",
      "Epoch 177/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 376686656.0000 - mae: 13967.0459 - val_loss: 405273312.0000 - val_mae: 14530.7520\n",
      "Epoch 178/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 376446912.0000 - mae: 13964.2119 - val_loss: 405439392.0000 - val_mae: 14531.9229\n",
      "Epoch 179/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 376607552.0000 - mae: 13953.8564 - val_loss: 405914752.0000 - val_mae: 14544.1396\n",
      "Epoch 180/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 376630560.0000 - mae: 13959.1904 - val_loss: 405993920.0000 - val_mae: 14544.3984\n",
      "Epoch 181/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 376321760.0000 - mae: 13950.3955 - val_loss: 405406208.0000 - val_mae: 14536.2881\n",
      "Epoch 182/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 376355456.0000 - mae: 13953.9287 - val_loss: 405318752.0000 - val_mae: 14524.0303\n",
      "Epoch 183/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 376323072.0000 - mae: 13954.2812 - val_loss: 405952864.0000 - val_mae: 14540.0801\n",
      "Epoch 184/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 375739008.0000 - mae: 13954.9326 - val_loss: 405901952.0000 - val_mae: 14541.3818\n",
      "Epoch 185/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 375754784.0000 - mae: 13947.3750 - val_loss: 406616736.0000 - val_mae: 14548.7588\n",
      "Epoch 186/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 376009088.0000 - mae: 13962.8721 - val_loss: 405740864.0000 - val_mae: 14536.7852\n",
      "Epoch 187/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 376199328.0000 - mae: 13960.0225 - val_loss: 406008096.0000 - val_mae: 14549.2588\n",
      "Epoch 188/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 375806080.0000 - mae: 13949.1396 - val_loss: 406261088.0000 - val_mae: 14553.5000\n",
      "Epoch 189/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 376025856.0000 - mae: 13950.0967 - val_loss: 406086112.0000 - val_mae: 14542.9287\n",
      "Epoch 190/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 375305024.0000 - mae: 13942.4746 - val_loss: 407597408.0000 - val_mae: 14570.7695\n",
      "Epoch 191/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 375458432.0000 - mae: 13943.6611 - val_loss: 406074912.0000 - val_mae: 14540.0986\n",
      "Epoch 192/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 375327328.0000 - mae: 13942.2803 - val_loss: 406186688.0000 - val_mae: 14544.0498\n",
      "Epoch 193/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 375652928.0000 - mae: 13943.8789 - val_loss: 406983808.0000 - val_mae: 14550.2949\n",
      "Epoch 194/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 375849312.0000 - mae: 13946.4863 - val_loss: 407568672.0000 - val_mae: 14578.5117\n",
      "Epoch 195/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 375595552.0000 - mae: 13940.7412 - val_loss: 406918528.0000 - val_mae: 14548.4229\n",
      "Epoch 196/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 375103392.0000 - mae: 13935.7588 - val_loss: 406453184.0000 - val_mae: 14540.8604\n",
      "Epoch 197/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 375707520.0000 - mae: 13946.1875 - val_loss: 406510976.0000 - val_mae: 14557.0752\n",
      "Epoch 198/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 375317120.0000 - mae: 13942.8027 - val_loss: 408525632.0000 - val_mae: 14564.2363\n",
      "Epoch 199/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 375270240.0000 - mae: 13943.7051 - val_loss: 406980128.0000 - val_mae: 14545.1768\n",
      "Epoch 200/200\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 375769888.0000 - mae: 13952.7861 - val_loss: 406548256.0000 - val_mae: 14546.7881\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 428344704.0000 - mae: 14902.2969\n",
      "\n",
      "Error Medio Absoluto en el test: $14902.30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step\n",
      "\n",
      "Comparación de Predicciones:\n",
      "Real: 76495 - Predicho: 70824.91\n",
      "Real: 191488 - Predicho: 179196.30\n",
      "Real: 130265 - Predicho: 123066.52\n",
      "Real: 167007 - Predicho: 156906.92\n",
      "Real: 115201 - Predicho: 102639.26\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "print(\"Entrenando la red neuronal...\")\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size=32, validation_split=0.2)\n",
    "\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nError Medio Absoluto en el test: ${mae:.2f}\")\n",
    "\n",
    "predicciones = model.predict(X_test[:5])\n",
    "print(\"\\nComparación de Predicciones:\")\n",
    "for i in range(5):\n",
    "    print(f\"Real: {y_test.values[i]} - Predicho: {predicciones[i][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ba690f1-f77e-4e9b-96de-d0a5cabb9f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(preprocessor, 'preprocesador.joblib')\n",
    "model.save('modelo_sueldos.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
